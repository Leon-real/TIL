### Selenium : 웹페이지 테스트 자동화

### Headless 크롬 : selenium을 통한 웹스크랩핑을 할 때, 브라우저 화면을 안띄우는 법(백그라운드에서 동작하는 것)

### 웹스크랩핑 요약

- HTML는뼈대, CSS는 예쁘게, JavaScript는 살아있게 ⇒ 이것이 웹이다.
- XPath : 웹안에 Element의 경로 (Chrome의 개발자 도구를 통해 쉽게 XPath를 쓸 수 있다.)
- 정규식 : 규칙을 가진 문자열을 표현하는 식
    1.  .  ⇒ (ab.d) 하나의 문자
    2. ^ ⇒ (^cd) 문자열의 시작
    3.  $ ⇒ ($cd) 문자열의 끝
    4.  match() ⇒ 처음부터 일치하는지
    5.  search() ⇒ 일치하는게 있는지
    6.  findall() ⇒ 일치하는 것 모두 리스트로
- User-Agent : 브라우저가 웹페이지를 요청할 때, 전달하는 헤더의 내용을 바탕으로 서버에서는 어떤페이지를 보여줄지 결정하는데, 일반적인 정보가 아닐때나 접근 권한이 없을 때, user-agent변경하여서 우회 접속 하는것.
- Requests : 웹 페이지(HTML)을 읽어오기 (빠르다, 동적인 웹 페이지에서는 사용불가)
    1. 주어진 url 을 통해서 받아온 html에 원하는 정보가 있을 때
- Selenium : 웹 페이지 자동화(느리다, 동적 웹페이지에서도 사용 가능)
    1. 로그인, 어떤 결과에 대한 필터링 등 어떤 동작을 해야 하는 경우
    2. 페이지에 대한 로딩(동적인 페이지)에 따른 기다림이 필요할 수 있다.
    3. Headless Chrome : 브라우저를 띄우지 않고 동작(때로는 User-Agent 필요)
- BeautifulSoup : 원하는 데이터 추출(웹 스크랩핑)

—

- 이미지 다운로드 : with open("파일명", "wb") as f: f.write(res.content)
- CSV

    import csv

    f = open(filename, "w", encoding="utf-8-sig", newline="")

—

중요 

⇒ 무분별한 웹 크롤링 또는 웹 스크랩핑은 대상 서버에 과부하를 줄 수 있다. → 계정 혹은 IP 차단

⇒ 데이터 사용주의 → 이미지, 텍스트 등 데이터 무단 활용 시 저작권 등 침해 요소, 법적 제재

⇒ robots.txt → 법적 효력은 없으나, 대상 사이트에서 권고

---
