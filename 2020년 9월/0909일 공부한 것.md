# 케라스를 사용하여 손글씨 숫자 분류를 위한 신경망 만들기
## 텐서플로우의 사용 및 간단한 구조 공부

---
```python
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
# x_train에는 손글씨 숫자의 이미지가 대입, y_train에는 이미지가 의미하는 숫자가 대입
# 훈련 데이터셋과 테스트 데이터셋을 구분하는 이유 : 모델을 학습시에는 훈련데이터 셋 이용, 모델의 예측 정확도를 평가시에는 테스트 데이터 사용
# 학습과 정확도 평가에 같은 데이터셋을 사용하면, 모델의 입력으로 사용된 데이터에만 예측이 잘되는 오버피팅 발생할 수 있다.

# x_train에 있는 손글씨 이미지를 제공하면, 모델의 출력인 y_train에 대응하는 숫자가 되도록 모델을 학습시키도록 한다.

x_train, x_test = x_train/255.0, x_test/255.0 # 손글씨 이미지 데이터는 0~255 사이의 값을 가짐(픽셀 값)

# 모델 초기화 하기
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28,28)), # 크기 28x28의 배열을 입력받아 1차원 배열로 변환
    tf.keras.layers.Dense(128, activation='relu'), # 히든 레이어의 갯수 128개, 활성화 함수 relu를 사용
    tf.keras.layers.Dropout(0.2), # 오버피팅을 방지하기위해, 무작위로 이전 레이어의 출력을 20% 끄기
    tf.keras.layers.Dense(10, activation='softmax') # 출력 레이어의 노드 갯수는 10개, softmax의 활성화 함수 사용
])
# softmax를 사용하면, 출력값 간의 편차가 커져서 분류하기 쉽게 된다.

# 옵티마이저, 손실 함수, 메트릭을 선택하기
model.compile(
    optimizer='adam', # 옵티마이저는 경사하강법(Gradient Descent)를 개선한 것
    loss='sparse_categorical_crossentropy', # 모델의 출력이 one-hot 엔코딩되어 있다면-> categorical_crossentropy를 사용, 모델의 출력이 정수라면 -> sparse_categorical_crossentropy를 사용
    metrics=['accuracy'] # 메트릭은 모델을 평가할 때 사용된다. 정확도로 설정
)

model.fit(x_train, y_train, epochs=5) # 학습 데이터셋을 사용하여, 모델을 5번 학습시킨다.
model.evaluate(x_test, y_test, verbose=2) # 테스트 데이터셋을 사용하여, 모델을 평가한다.
```
