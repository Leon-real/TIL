# 모두를 위한 딥러닝 강좌 (강의 3~4까지)

### Gradient descent algorithm (경사하강 알고리즘)

- Minimize cost function
- Gradient descent is used many minimization problems
- For a given cost function, cost(W,b), it will find W,b, to minimize cost
- It can be applied to more general function:cost

### Multi-variable linear regression(다중 선형 회기)

- Linear regression 위해 필요한 3가지
    1. Hypothesis : 가설이 무엇인가 ⇒ 내가 어떻게 예측할 것인지를 나타내는 것
    2. cost function : 가설을 통해 내가 W,b를 잘 계산했는지 아닌지를 판단하는 함수
    3. Gradient descent Algorithm : cost function을 최적화 하는 알고리즘

Multi-variable linear regression은 여러개의 값에 영향을 받는 한개의 값을 찾는 것을 찾는것이라 보면 된다

그런데 이러한 많은 값들을 처리하기에 힘들지 않을까? ⇒ 그래서 나온 방법이 matrix로 표현하여 처리하는 것이다
